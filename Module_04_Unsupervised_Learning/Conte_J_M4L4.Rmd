---
title: "M4L4 Homework Assignment"
author: "Joshua Conte"
date: "October 15, 2017"
output: 
  pdf_document:
    fig_caption: true
header-includes:
    - \usepackage{fancyhdr}
    - \pagestyle{fancy}
    - \fancyhead[CO,CE]{DA5030}
    - \fancyfoot[CO,CE]{Assignment M4L4 by Joshua Conte}
    - \fancyfoot[LE,RO]{\thepage}
---

```{r setup, include=FALSE}
library(knitr)
knitr::opts_chunk$set(echo = TRUE)
```

&nbsp;


\clearpage
\setcounter{secnumdepth}{5}
\setcounter{tocdepth}{5}
\pagebreak

# M4L4 Homework Assignment
R studio was configured with the following parameters before beginning the project:
```{r Configure RStudio, warning = FALSE, message = FALSE}
# clears the console in RStudio
cat("\014") 

# clears environment
rm(list = ls())  

# Load required packages
require(arules)
require(arulesViz)
```

## Load Data.   
I used the "Income" database that comes with the [arules](https://cran.r-project.org/web/packages/arules/index.html) package.

This data set originates from an example in the book 'The Elements of Statistical Learning' (see Section source). The data set is an extract from this survey. It consists of 8993 instances (obtained from the original data set with 9409 instances, by removing those observations with the annual income missing) with 14 demographic attributes. The data set is a good mixture of categorical and continuous variables with a lot of missing data. This is characteristic of data mining applications. The Income data set contains the data already prepared and coerced to transactions.

Below is my R code:
```{r open and format the dataset}
data("Income")
summary(Income)
```

###Format
Income data set contains 8993 observations on the following 14 variables:

* **income** an ordered factor with levels [0,10) < [10,15) < [15,20) < [20,25) < [25,30) < [30,40) < [40,50) < [50,75) < 75+
* **sex** a factor with levels male female
* **marital status** a factor with levels married cohabitation divorced widowed single
* **age** an ordered factor with levels 14-17 < 18-24 < 25-34 < 35-44 < 45-54 < 55-64 < 65+
* **education** an ordered factor with levels grade <9 < grades 9-11 < high school graduate < college (1-3 years) < college graduate < graduate study
* **occupation** a factor with levels professional/managerial sales laborer clerical/service homemaker student military retired unemployed
* **years in bay area** an ordered factor with levels <1 < 1-3 < 4-6 < 7-10 < >10
* **dual incomes** a factor with levels not married yes no
* **number in household** an ordered factor with levels 1 < 2 < 3 < 4 < 5 < 6 < 7 < 8 < 9+
* **number of children** an ordered factor with levels 0 < 1 < 2 < 3 < 4 < 5 < 6 < 7 < 8 < 9+
* **householder status** a factor with levels own rent live with parents/family
* **type of home** a factor with levels house condominium apartment mobile Home other
* **ethnic classification** a factor with levels American Indian Asian Black East Indian Hispanic pacific islander white other
* **language in home** a factor with levels English Spanish other

##Analyzing the Data
Look at the first five transactions.
```{r inspect the data}
# look at the first five transactions
inspect(Income[1:5])
```

Plot the frequency.
```{r Plot the frequency}
# plot the frequency 
# if getting the error
# Error in plot.new() : figure margins too large in RStudio
# use dev.off() to Rrsetting your graphics device 
# dev.off() will remove any leftover options or settings 
# 
itemFrequencyPlot(Income, support = 0.1)
itemFrequencyPlot(Income, topN = 20)
```

Visualization of some of the transactions.
```{r Visualization the data}
# a visualization of first ten transactions
image(Income[1:10])
# visualization of a random sample of 100 transactions
image(sample(Income, 100))
```


## Apriori algorithm  
I began with the values: support = 0.01, confidence = 0.99, and mionlen = 4.  Then I started adjusting the support value so that when the redundancies were removed the final set of rules would be around 50. I eventually set the support value to 0.17.

To find the redundancies, I found using *is.redundant()* is much more efficient and faster than using the example in the module.  Before removing the redundancies, I sorted the rules by lift.

Below is my R code:
```{r Get 50 rules}
# set better support and confidence levels to get around 50 rules
income <-
  apriori(Income, parameter = list(
    support = 0.17,
    confidence = 0.99,
    minlen = 4
  ))
summary(income)

# sort by lift
rules.sorted<-sort(income, by = "lift")

# A more efficient way to find redundant rules
redundant<- is.redundant(rules.sorted)
summary(redundant)

# Remove redundant rules
rules.pruned <- rules.sorted[!redundant]

# Verify rules
rules.pruned

# Print rules
inspect(rules.pruned)
```

Visualizing Association Rules:
```{r Visualizing the rules}
plot(rules.pruned)
plot(rules.pruned, method="graph", control=list(type="items"))
plot(rules.pruned, method="paracoord", control=list(reorder=TRUE))
```
Calculating lift and conviction:
```{r lift and conviction}
# Lift and conviction for the first five rules. Note, the number convention is worng.
cbind(
  as(rules.pruned[1:5], "data.frame"),
  conviction = interestMeasure(rules.pruned[1:5], "conviction", rules.pruned[1:5])
)

# Lift and conviction for the last five rules. Note, the number convention is worng.
cbind(
  as(rules.pruned[49:53], "data.frame"),
  conviction = interestMeasure(rules.pruned[49:53], "conviction", rules.pruned[49:53])
)
```

##Questions
1. **Which rules make sense to you? Highlight the five best and five worst of your rule set.**
    + Reviewing the rules, they all make sense to me.  I think that they are all ok, so for this question I am going to choose 1 - 5 as the best and 49 - 53 as the worst.
    + **The Best:**
           1.  {marital status=single, age=14-34, householder status=live with parents/family} => {dual incomes=not married}
           2.  {marital status=single, education=no college graduate, householder status=live with parents/family} => {dual incomes=not married}
           3.  {sex=male, marital status=single, age=14-34} => {dual incomes=not married}
           4.  {sex=male, marital status=single, language in home=english} => {dual incomes=not married}
           5.  {sex=female, marital status=single, age=14-34} => {dual incomes=not married}
    + **The Worst**
           49. {sex=female, number in household=1, ethnic classification=white} => {language in home=english}
           50. {age=35+, years in bay area=10+, ethnic classification=white} > {language in home=english}
           51. {number of children=0, type of home=house, ethnic classification=white} => {language in home=english}
           52. {age=35+, type of home=house, ethnic classification=white} => {language in home=english}
           53. {marital status=married, householder status=own, ethnic classification=white} => {language in home=english}
2. **How did you choose the level of support and confidence?**
    + I began with the values: support = 0.01, confidence = 0.99, and mionlen = 4.  Then I started adjustingthe support value so that when the redundancies were removed the final set of rules would be around 50. . I settled on 0.17 for support and 0.99 for confidence.
3. **What is the lift and conviction of your best and worst rules?**
    + **The Best:**
           1.  lift 1.671366 / conviction NA
           2.  lift 1.671366 / conviction NA
           3.  lift 1.671366 / conviction NA
           4.  lift 1.671366 / conviction NA
           5.  lift 1.671366 / conviction NA
    + **The Worst**
           49. lift 0.2696335 / conviction 9.059919
           50. lift 0.2367656 / conviction 8.951025
           51. lift 0.2334206 / conviction 8.825798
           52. lift 0.2181501 / conviction 8.798575
           53. lift 0.2028796 / conviction 8.767462
4. **Visualize your 50 association rules. Where do the best and worst end up in your plot?**
    + The first five are high confidence with low support, so they are all in the upper left corner of the scatter plot.  The last five are higher support with lower confidence, which are the ones on the lower middle/right of the scatter plot.  
5. **Does the model make sense?**
    + Yes the model makes sense, the first five rules are all single with a single income, that makes sense, usually a single person does not have duel incomes.  The last five rules also make sense, they all live in California and are white and the household language is English, I think that makes sense. After reviewing all of the rules, nothing jumped out at me as being strange or misclassified.